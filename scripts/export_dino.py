import torch
import torch.nn as nn
import os
import yaml
import sys

# ==========================================
# 1. Wrapper Class
# ==========================================
class DinoWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def forward(self, x):
        # DINOv2 ‡∏à‡∏≤‡∏Å Torch Hub ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Tensor (Batch, Embed_Dim) ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        return self.model(x)

def export_model():
    print("üöÄ Starting DINOv2 Export Process...")

    # ==========================================
    # 2. Setup Paths & Load Config
    # ==========================================
    # ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Root Project (‡∏ñ‡∏≠‡∏¢‡∏à‡∏≤‡∏Å scripts/ ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ 1 ‡∏ä‡∏±‡πâ‡∏ô)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir) 
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡πà root ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ: project_root = script_dir
    
    config_path = os.path.join(project_root, "config.yaml")
    
    # ‡∏Ñ‡πà‡∏≤ Default
    ai_size = 336 

    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå config.yaml
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r') as f:
                cfg = yaml.safe_load(f)
                # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á: settings -> ai_size
                ai_size = cfg.get('settings', {}).get('ai_size', 336)
            print(f"üìñ Loaded Config from {config_path}")
            print(f"üéØ Target AI Size: {ai_size}x{ai_size}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error loading config: {e}. Using default {ai_size}.")
    else:
        print(f"‚ö†Ô∏è Config file not found at {config_path}. Using default {ai_size}.")

    # ==========================================
    # 3. Load & Prepare Model
    # ==========================================
    print("‚è≥ Downloading DINOv2 (ViT-B/14) from Torch Hub...")
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ô‡πá‡∏ï‡∏ä‡πâ‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡πá‡∏Å ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 'dinov2_vits14' (Small)
    raw_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')
    raw_model.eval()
    
    model = DinoWrapper(raw_model)

    # üî• SENIOR TRICK: ‡πÉ‡∏ä‡πâ Batch Size = 2 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡πâ‡∏≥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Dynamic Batch
    dummy_input = torch.randn(2, 3, ai_size, ai_size)
    
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Output Path
    output_dir = os.path.join(project_root, "models")
    output_file = os.path.join(output_dir, "dinov2_vitb14.onnx")
    os.makedirs(output_dir, exist_ok=True)

    print(f"üì¶ Exporting to ONNX at: {output_file}...")
    
    # ==========================================
    # 4. Export
    # ==========================================
    try:
        torch.onnx.export(
            model, 
            dummy_input, 
            output_file,
            export_params=True, 
            opset_version=14,        # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 17 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Transformer ‡∏¢‡∏∏‡∏Ñ‡πÉ‡∏´‡∏°‡πà
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            # ‚úÖ ‡∏û‡∏£‡∏∞‡πÄ‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤: ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏Å‡∏ô 0 (Batch) ‡∏¢‡∏∑‡∏î‡∏´‡∏î‡πÑ‡∏î‡πâ
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        print("-" * 50)
        print(f"‚úÖ SUCCESS! Model Exported.")
        print(f"üìÇ Location: {output_file}")
        print(f"üìê Input Size: {ai_size}x{ai_size}")
        print(f"üîÑ Dynamic Batch: Enabled (Ready for batch processing)")
        print("-" * 50)
        
    except Exception as e:
        print(f"‚ùå Export Failed: {e}")

if __name__ == "__main__":
    export_model()